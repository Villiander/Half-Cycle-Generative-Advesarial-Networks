{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3863247,"sourceType":"datasetVersion","datasetId":2296461}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom torchvision import transforms as T\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport torch\n\n# Directory and file setup\nimage_dir = \"/kaggle/input/glaucoma-datasets/G1020/Images\"\nmetadata_file = \"/kaggle/input/glaucoma-datasets/G1020/G1020.csv\"\n\n# Load metadata\nmetadata = pd.read_csv(metadata_file)\nmetadata['path'] = metadata['imageID'].apply(lambda x: os.path.join(image_dir, x))\n\n# Separate data by class\nglaucoma_df = metadata[metadata['binaryLabels'] == 1]\nnormal_df = metadata[metadata['binaryLabels'] == 0]\n\n# Ensure equal number of samples from each class\nmin_samples = min(len(glaucoma_df), len(normal_df))\n\n# Randomly sample without replacement from each class\nglaucoma_df = glaucoma_df.sample(n=min_samples, random_state=42)\nnormal_df = normal_df.sample(n=min_samples, random_state=42)\n\n# Concatenate the balanced data\nbalanced_df = pd.concat([glaucoma_df, normal_df]).reset_index(drop=True)\n\n# Split the balanced dataset into train and test sets\ntrain_df, test_df = train_test_split(balanced_df, test_size=0.2, random_state=42, stratify=balanced_df['binaryLabels'])\n\n# Image transformations\ntransformations = T.Compose([\n    T.RandomResizedCrop(224),\n    T.RandomHorizontalFlip(),\n    T.ToTensor(),\n    #T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Custom dataset class\nclass GlaucomaDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        img_path = self.dataframe.iloc[idx]['path']\n        image = Image.open(img_path).convert(\"RGB\")\n        label = self.dataframe.iloc[idx]['binaryLabels']\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n# Create datasets and dataloaders\nglaucoma_dataset = GlaucomaDataset(glaucoma_df, transform=transformations)\nnormal_dataset = GlaucomaDataset(normal_df, transform=transformations)\n\nglaucoma_loader = DataLoader(glaucoma_dataset, batch_size=32, shuffle=True)\nnormal_loader = DataLoader(normal_dataset, batch_size=32, shuffle=True)\n# This setup ensures that both the training and testing sets are balanced regarding class distribution","metadata":{"execution":{"iopub.status.busy":"2024-12-10T09:04:08.124933Z","iopub.execute_input":"2024-12-10T09:04:08.125262Z","iopub.status.idle":"2024-12-10T09:04:16.564055Z","shell.execute_reply.started":"2024-12-10T09:04:08.125224Z","shell.execute_reply":"2024-12-10T09:04:16.563264Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    \n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.downsample = nn.Sequential(\n            # input: 3 x 256 x 256\n            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1), # output: 64 x 128 x 128\n            nn.ReLU(True),\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1), # output: 128 x 64 x 64\n            nn.BatchNorm2d(128),\n            nn.ReLU(True),\n            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1), # output: 256 x 32 x 32\n            nn.BatchNorm2d(256),\n            nn.ReLU(True),\n            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1), # output: 512 x 16 x 16\n            nn.BatchNorm2d(512),\n            nn.ReLU(True)\n        )\n        self.upsample = nn.Sequential(\n        \n            nn.Upsample(scale_factor=2, mode='nearest'), # output: 512 x 32 x 32\n            conv3x3(512, 256), \n            nn.BatchNorm2d(256),\n            nn.ReLU(True),\n            nn.Upsample(scale_factor=2, mode='nearest'), # output: 256 x 64 x 64\n            conv3x3(256, 128),\n            nn.BatchNorm2d(128),\n            nn.ReLU(True),\n            nn.Upsample(scale_factor=2, mode='nearest'), # output: 128 x 128 x 128\n            conv3x3(128, 64),\n            nn.BatchNorm2d(64),\n            nn.ReLU(True),\n            nn.Upsample(scale_factor=2, mode='nearest'), # output: 64 x 256 x 256\n            conv3x3(64, 3),\n            nn.Tanh()  # Final output: 3 x 256 x 256\n        )\n\n    def forward(self, x):\n        x = self.downsample(x)\n        x = self.upsample(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-12-10T09:04:34.198087Z","iopub.execute_input":"2024-12-10T09:04:34.198789Z","iopub.status.idle":"2024-12-10T09:04:34.209375Z","shell.execute_reply.started":"2024-12-10T09:04:34.198761Z","shell.execute_reply":"2024-12-10T09:04:34.208478Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.main = nn.Sequential(\n            # Input: 224 x 224\n            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),  # Output: 112 x 112\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),  # Output: 56 x 56\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),  # Output: 28 x 28\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),  # Output: 14 x 14\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(512, 1024, kernel_size=4, stride=2, padding=1),  # Output: 7 x 7\n            nn.BatchNorm2d(1024),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(1024, 2048, kernel_size=4, stride=2, padding=1),  # Output: 3 x 3 (rounded from 3.5 x 3.5)\n            nn.BatchNorm2d(2048),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(2048, 1, kernel_size=3, stride=1, padding=0),  # Output: 1 x 1\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):\n        output = self.main(input)\n        return output.view(-1)  # Flatten the output to ensure it is [batch_size]","metadata":{"execution":{"iopub.status.busy":"2024-12-10T09:04:37.832167Z","iopub.execute_input":"2024-12-10T09:04:37.832515Z","iopub.status.idle":"2024-12-10T09:04:37.840337Z","shell.execute_reply.started":"2024-12-10T09:04:37.832492Z","shell.execute_reply":"2024-12-10T09:04:37.839332Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport os\nfrom IPython.display import display\n\ndef visualize_images(real_images, transformed_images, epoch, save_dir='/kaggle/working'):\n    real_images = real_images.detach().cpu()\n    transformed_images = transformed_images.detach().cpu()\n    \n    fig, axes = plt.subplots(nrows=2, ncols=8, figsize=(16, 4))\n    for i in range(8):\n        axes[0, i].imshow(real_images[i].permute(1, 2, 0))\n        axes[0, i].axis('off')\n        axes[1, i].imshow(transformed_images[i].permute(1, 2, 0))\n        axes[1, i].axis('off')\n\n    plt.show()  # Display the figure in the output cell\n    plt.savefig(os.path.join(save_dir, f'epoch_{epoch+1}.png'))  # Save the figure to the file system\n    plt.close(fig)  # Close the figure to free memory","metadata":{"execution":{"iopub.status.busy":"2024-12-10T09:04:41.047397Z","iopub.execute_input":"2024-12-10T09:04:41.047713Z","iopub.status.idle":"2024-12-10T09:04:41.054332Z","shell.execute_reply.started":"2024-12-10T09:04:41.047690Z","shell.execute_reply":"2024-12-10T09:04:41.053405Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nlambda1_values = [1.0]\ndef train_gan_for_lambda(generator, discriminator, glaucoma_loader, normal_loader, lambda1_values, num_epochs=100, save_dir='/kaggle/working'):\n    mse_loss = nn.MSELoss()\n    l1_loss = nn.L1Loss()  # Adding L1 Loss for perceptual similarity\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    loss_dict = {f'lambda_{lambda1:.1f}': {'D': [], 'G': []} for lambda1 in lambda1_values}\n\n    for lambda1 in lambda1_values:\n        print(f\"Training with lambda1 = {lambda1}\")\n        \n        # Reinitialize the optimizers and schedulers for each lambda value\n        optimizerD = optim.Adam(discriminator.parameters(), lr=0.00002, betas=(0.5, 0.999))\n        optimizerG = optim.Adam(generator.parameters(), lr=0.00002, betas=(0.5, 0.999))\n        schedulerD = torch.optim.lr_scheduler.StepLR(optimizerD, step_size=10, gamma=0.1)\n        schedulerG = torch.optim.lr_scheduler.StepLR(optimizerG, step_size=10, gamma=0.1)\n\n        generator.to(device)\n        discriminator.to(device)\n\n        real_label = 1.0\n        fake_label = 0.0\n\n        for epoch in range(num_epochs):\n            running_lossD = 0.0\n            running_lossG = 0.0\n            \n            for glaucoma_data, normal_data in zip(glaucoma_loader, normal_loader):\n                # Unpack the batches correctly\n                normal_images, _ = normal_data\n                glaucoma_images, _ = glaucoma_data\n                normal_images = normal_images.to(device)\n                glaucoma_images = glaucoma_images.to(device)\n                \n                batch_size = normal_images.size(0)\n\n                # Train Discriminator on real images\n                real_outputs = discriminator(normal_images)\n                lossD_real = mse_loss(real_outputs, torch.full((batch_size,), real_label, dtype=torch.float, device=device))\n\n                # Generate fake images from glaucoma data\n                fake_images = generator(glaucoma_images)\n                fake_outputs = discriminator(fake_images.detach())\n                lossD_fake = mse_loss(fake_outputs, torch.full((batch_size,), fake_label, dtype=torch.float, device=device))\n\n                # Update Discriminator\n                discriminator.zero_grad()\n                lossD = (lossD_real + lossD_fake) / 2\n                lossD.backward()\n                optimizerD.step()\n\n                # Update Generator with perceptual loss\n                generator.zero_grad()\n                output_gen = discriminator(fake_images)\n                lossG = mse_loss(output_gen, torch.full((batch_size,), real_label, dtype=torch.float, device=device))\n                perceptual_loss = l1_loss(fake_images, glaucoma_images)  # Enforcing similarity\n                total_gen_loss = lossG + lambda1 * perceptual_loss  # Combine losses with a weighting factor\n                total_gen_loss.backward()\n                optimizerG.step()\n\n                running_lossD += lossD.item()\n                running_lossG += total_gen_loss.item()\n\n            loss_dict[f'lambda_{lambda1:.1f}']['D'].append(running_lossD / len(glaucoma_loader))\n            loss_dict[f'lambda_{lambda1:.1f}']['G'].append(running_lossG / len(glaucoma_loader))\n\n            if (epoch + 1) % 10 == 0:\n                print(f'Epoch {epoch+1}/{num_epochs}: '\n                      f'Loss_D: {running_lossD / len(glaucoma_loader):.4f}, Loss_G: {running_lossG / len(glaucoma_loader):.4f}, '\n                      f'Perceptual Loss: {perceptual_loss.item():.4f}, '\n                      f'D(x): {real_outputs.mean().item():.4f}, D(G(z)): {fake_outputs.mean().item():.4f} / {output_gen.mean().item():.4f}')\n                \n                # Visualize images\n                with torch.no_grad():\n                    visualize_images(glaucoma_images[:8], fake_images[:8], epoch, save_dir)\n\n            schedulerD.step()\n            schedulerG.step()\n\n        # Save model weights after training with the current lambda1 value\n        torch.save(generator.state_dict(), os.path.join(save_dir, f'generator_lambda_{lambda1:.1f}.pth'))\n        torch.save(discriminator.state_dict(), os.path.join(save_dir, f'discriminator_lambda_{lambda1:.1f}.pth'))\n\n    # Plotting the losses for all lambdas\n    plt.figure(figsize=(10, 7))\n    for lambda1 in lambda1_values:\n        plt.plot(range(1, num_epochs + 1), loss_dict[f'lambda_{lambda1:.1f}']['D'], label=f'D_loss_lambda_{lambda1:.1f}')\n        plt.plot(range(1, num_epochs + 1), loss_dict[f'lambda_{lambda1:.1f}']['G'], label=f'G_loss_lambda_{lambda1:.1f}')\n\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title('Loss vs. Epochs for different lambda values')\n    plt.legend()\n    plt.grid(True)\n    plt.savefig(os.path.join(save_dir, 'loss_vs_epochs.png'))\n    plt.show()\n    \ngenerator = Generator().to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\ndiscriminator = Discriminator().to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n# Call the training function\ntrain_gan_for_lambda(generator, discriminator, glaucoma_loader, normal_loader, lambda1_values, 100, '/kaggle/working')","metadata":{"execution":{"iopub.status.busy":"2024-12-10T09:05:28.973507Z","iopub.execute_input":"2024-12-10T09:05:28.973818Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Training with lambda1 = 1.0\n","output_type":"stream"}],"execution_count":null}]}